{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77ba0b2b-ce00-4163-8d1a-e5abc93bb40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import HuberRegressor, Ridge\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.datasets import make_gaussian_quantiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "199521e9-951e-4e2e-997c-d755ff477543",
   "metadata": {},
   "source": [
    "# SKlearn (Dataset loading utilities)\n",
    "\n",
    "The `sklearn.datasets` package includes:\n",
    "\n",
    "* some small toy datasets\n",
    "* larger datasets commonly used by the machine learning community to benchmark algorithms on data that comes from the 'real world'.\n",
    "\n",
    "To evaluate the impact of the scale of the dataset (`n_samples` and `n_features`) while controlling the statistical properties of the data (typically the correlation and informativeness of the features), it is also possible to generate synthetic data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d98b0872-fae2-450e-9baf-d97270491f70",
   "metadata": {},
   "source": [
    "# General Dataset API\n",
    "There are three main kinds of dataset interfaces that can be used to get datasets depending on the desired type of dataset.\n",
    "\n",
    "*   The dataset **loaders**: to load small standard datasets\n",
    "*   The dataset **fetchers**: to download and load larger datasets\n",
    "*   The dataset **generation functions**: to generate controlled synthetic datasets\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa95edfb-732c-40d0-8fcc-c3f711d61151",
   "metadata": {},
   "source": [
    "**Tip**: These functions return a tuple (X, y) consisting of a n_samples * n_features numpy array X and an array of length n_samples containing the targets y.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0f9cdb-84d7-40e1-a313-0af963e5f98b",
   "metadata": {},
   "source": [
    "## Loaders (Toy datasets)\n",
    "- Boston house prices dataset\n",
    "- Iris plants dataset\n",
    "- Diabetes dataset\n",
    "- Optical recognition of handwritten digits dataset\n",
    "- Linnerrud dataset (twenty middle-aged men in a fitness club)\n",
    "- Wine recognition dataset\n",
    "- Breast cancer wisconsin (diagnostic) dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a02f04e-e452-44b5-a4cd-d683738f01d4",
   "metadata": {},
   "source": [
    "## Fetchers (Real world datasets)\n",
    "- The Olivetti faces dataset\n",
    "- The 20 newsgroups text dataset\n",
    "- The Labeled Faces in the Wild face recognition dataset\n",
    "- Forest covertypes\n",
    "- RCV1 dataset\n",
    "- Kddcup 99 dataset\n",
    "- California Housing dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74dbf862-e2a2-49b0-8269-b31478c2c320",
   "metadata": {},
   "source": [
    "## Generated datasets\n",
    "- Generators for classification and clustering\n",
    "- Generators for regression\n",
    "- Generators for manifold learning\n",
    "- Generators for decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23f112ed-98d0-4cca-ab49-0110819cc885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
